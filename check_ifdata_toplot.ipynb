{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cd4ec1-320e-4eb0-8721-6e26235e4600",
   "metadata": {},
   "source": [
    "## Still Drafting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5807c-0c7c-43ec-b067-2bdcc38b6df0",
   "metadata": {},
   "source": [
    "### Working copy of a script to check if a path for storing data exists, if the desired time range is already downloaded, and if not, gets and saves data from IRIS, then plots RSAM, Spectrogram, PPSDs, and Temporal Plots for each day within the specified time range. Ideally allows for inputting larger time ranges and getting 1 plot per day. \n",
    "### Currently works as normal for already saved data, but still some issues with clean/full outputs of the data it downloads via the script. Polished version TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f3694-8a86-452c-a7a5-c45d5459dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing reading and displaying plots as each day's data is processed but error with downloading section\n",
    "\n",
    "import obspy\n",
    "from obspy import UTCDateTime, read\n",
    "from obspy.signal import PPSD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.imaging.cm import pqlx\n",
    "import os\n",
    "from obspy.clients.fdsn import Client\n",
    "from datetime import timedelta\n",
    "from obspy.clients import fdsn\n",
    "import warnings\n",
    "\n",
    "# define start and end time for the data range\n",
    "start_date = UTCDateTime(2023, 8, 25)  # Start time\n",
    "end_date = UTCDateTime(2023, 8, 27)  # End time\n",
    "delta = 86400  # one day\n",
    "download_delta = 1800  # 30 minutes per data chunk\n",
    "stas = [2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, \n",
    "        'G2301', 'G2302', 'G2303', 'G2304', 'G2305', 'G2306', 'G2307', 'G2308', 'G2309', 'G2310', 'G2311',\n",
    "        'G2312', 'G2313', 'G2314', 'G2315', 'G2316'] \n",
    "\n",
    "stas = ['ZE.2304..GPZ']\n",
    "\n",
    "# define path where .mseed files are stored\n",
    "path = 'C:/Users/zzawol/Documents/seismic-data-iris/seismic_data/NO2304/GPZ'\n",
    "\n",
    "# IRIS credentials\n",
    "username = 'zoe_zawol@partner.nps.gov'\n",
    "password = 'rJXKed4LZUHUE05g'\n",
    "\n",
    "# set station info\n",
    "nowsta = stas[0]\n",
    "network, station, location, channel = nowsta.split('.')\n",
    "print(f\"Using station: {nowsta}\")\n",
    "\n",
    "# define the file pattern for reading mseed files\n",
    "file_pattern = f'{path}/{network}.{station}.*.{channel}*.mseed'\n",
    "\n",
    "# function to check if files for a specific date are present in the directory\n",
    "def check_files_for_day(path, day_start_time):\n",
    "    files = os.listdir(path)\n",
    "    required_files = set()\n",
    "\n",
    "    # check if any files for the given day exist\n",
    "    day_str = day_start_time.strftime('%Y%m%d')\n",
    "    for file in files:\n",
    "        if day_str in file:  # check if the file is for this day\n",
    "            return True  # files exist for this day\n",
    "\n",
    "    return False  # files are missing for this day\n",
    "\n",
    "# IRIS client setup\n",
    "DATASELECT = 'http://service.iris.edu/ph5ws/dataselect/1'\n",
    "c = fdsn.client.Client(service_mappings={'dataselect': DATASELECT})\n",
    "c.set_credentials(username, password)\n",
    "\n",
    "# check if path exists and if files are within the given time range -- add create path in else\n",
    "if os.path.isdir(path):\n",
    "    print(\"Path exists. Checking for files within the time range...\")\n",
    "\n",
    "    # loop through each day in the date range\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        print(f\"\\nProcessing data for {current_date} to {current_date + delta}\")\n",
    "\n",
    "        # store traces for the full day\n",
    "        day_tr = []\n",
    "\n",
    "        # check if data for the current day exists\n",
    "        if check_files_for_day(path, current_date):\n",
    "            print(f\"Files for {current_date.strftime('%Y%m%d')} already exist. Reading data from disk.\")\n",
    "            try:\n",
    "                # read all data for the current day in one go\n",
    "                S = obspy.read(file_pattern, starttime=current_date, endtime=current_date + delta)\n",
    "                S.merge(method=1)\n",
    "                print(\"Resampling...\")\n",
    "                S.resample(100) # resample for PPSD\n",
    "                day_tr.extend(S) # add to list\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading data for {current_date}: {e}\")\n",
    "        else:\n",
    "            # if data for current day is missing, download it\n",
    "            print(f\"Downloading missing data for {current_date.strftime('%Y%m%d')}\")\n",
    "            tNow = current_date\n",
    "            req = [] #UNSURE??\n",
    "            while tNow < current_date + delta:\n",
    "                try:\n",
    "                    print(f\"  Downloading data for {tNow} to {tNow + download_delta}\")\n",
    "                    S = c.get_waveforms(network, station, location, channel, tNow, tNow + download_delta)\n",
    "                    if S:\n",
    "                        # set up metadata\n",
    "                        client = Client(\"IRISPH5\")\n",
    "                        inv = client.get_stations(network=network, station=station, location=location, channel=channel, level='response')\n",
    "                        print(\"Resampling for download - 350 Hz\")\n",
    "                        S.resample(350)  # resampled rate for final analysis. See Nyquist rules.\n",
    "                        S.merge(method=1) # merge traces to avoid duplicates\n",
    "\n",
    "                        # plotting RSAM and spectrogram\n",
    "                        f1 = waveformUtils.multiDaySpectrogram(S, averageLength=3600, fftLength=60, minFreq=0.5, maxFreq=150, cmap='turbo',\n",
    "                                      dateLimits=None,\n",
    "                                      vmin=0.4, vmax=0.9, plotAverage=True)\n",
    "                        f1.show()\n",
    "\n",
    "                        # # prefiltering for instrument's frequency bandwidth, do before preprocessing\n",
    "                        # for tr in S: # adjust to not read below 0.1 Hz?***\n",
    "                        #     pre_filt = [0.1, 1, 100, 150] # 4 corner frequencies # values TBD\n",
    "                        #     tr.remove_response(inventory=inv, pre_filt=pre_filt, plot=True) # , output=\"DISP\", water_level=60, plot=False)  \n",
    "    \n",
    "                        print(\"Resampling for PPSD analysis - 300 Hz\")\n",
    "                        S.resample(300)\n",
    "                        \n",
    "                        # save the data to files\n",
    "                        for tr in S:\n",
    "                            filename = f'{path}/{tr.id}_{tr.stats.starttime.strftime(\"%Y%m%d%H%M%S\")}.mseed'\n",
    "                            tr.write(filename)\n",
    "                            #print(f\"Data saved as {filename}\")\n",
    "                        day_tr.extend(S)  # store the traces for the full day\n",
    "                    else:\n",
    "                        print(f\"No data returned for {tNow} to {tNow + download_delta}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading data for {tNow} to {tNow + download_delta}: {e}\")\n",
    "                tNow += download_delta  # increment by 30 minutes to next time chunk\n",
    "\n",
    "        # now that the full day's data has been gathered, proceed with analysis and plotting\n",
    "        if day_tr:\n",
    "            # # merge traces to avoid duplicates  ### could leave these here to avoid repeating commands - but may not have worked for tr\n",
    "            # day_tr.merge(method=1)\n",
    "\n",
    "            # # resample the data\n",
    "            # print('Resampling...')\n",
    "            # day_tr.resample(100)  # Resampled rate for final analysis\n",
    "\n",
    "            # create PPSD object and add traces\n",
    "            ppsd = None\n",
    "            for tr in day_tr:\n",
    "                if ppsd is None:\n",
    "                    ppsd = PPSD(tr.stats, metadata=inv, ppsd_length=25*60, period_limits=(0.005, 10.0)) #3 try this length, if not try 20, or min(len(tr))\n",
    "                    print(f\"PPSD length: {25*60}\")\n",
    "                    print(f\"Min trace length: {np.min(len(tr))}\")\n",
    "                ppsd.add(tr)\n",
    "                #print('Trace added')\n",
    "\n",
    "            # plot the PPSD for the current day\n",
    "            if ppsd is not None and len(ppsd.times_processed) > 0:\n",
    "                print(f\"Data accumulated for {(end_date-start_date)/(60*60*24)}-day periods starting on {current_date.strftime('%Y%m%d')}\")\n",
    "                print(\"Processed times:\", ppsd.times_processed[:10])  # see first 10 times processed\n",
    "\n",
    "                # plot the PPSD\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                ppsd.plot(period_lim=(0.005,10),cmap=pqlx)\n",
    "                psd_values = ppsd.psd_values\n",
    "                print(\"Shape of psd values: \", np.shape(psd_values))\n",
    "\n",
    "                # plotting time series of PSD values\n",
    "                ppsd.plot_temporal([0.1, 1, 10])\n",
    "\n",
    "                plt.show()  # show the plot for the current day\n",
    "                plt.close()  # close plot to avoid displaying it in each iteration\n",
    "\n",
    "        # move to the next day\n",
    "        current_date += delta\n",
    "\n",
    "else:\n",
    "    print(f\"Path does not exist. Downloading data from IRIS and creating path...\")\n",
    "    DATASELECT = 'http://service.iris.edu/ph5ws/dataselect/1'\n",
    "    c = fdsn.client.Client(service_mappings={'dataselect': DATASELECT})\n",
    "    c.set_credentials(username, password)\n",
    "\n",
    "    # create directory if it doesn't exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # download data for the entire time range\n",
    "    tNow = start_date  # start time\n",
    "    while tNow < end_date:\n",
    "        print(f\"Downloading data for {tNow} to {tNow + delta}\")\n",
    "        try:\n",
    "            #warnings.filterwarnings(\"ignore\", message=\".*encoding.*\") # suppress download process warnings - otherwise shows up a ton\n",
    "            S = c.get_waveforms(network, station, location, channel, tNow, tNow + download_delta)\n",
    "            if S:\n",
    "                S.merge(method=1)\n",
    "                S.resample(350)\n",
    "                # save the data to files\n",
    "                for tr in S:\n",
    "                    filename = '{}/{}_{}.mseed'.format(path, tr.id, tr.stats.starttime.strftime('%Y%m%d%H%M%S'))\n",
    "                    tr.write(filename)\n",
    "                    #print(f\"Data saved as {filename}\")\n",
    "            else:\n",
    "                print(f\"No data returned for {tNow} to {tNow + download_delta}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for {tNow} to {tNow + download_delta}: {e}\")\n",
    "        tNow += download_delta\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
